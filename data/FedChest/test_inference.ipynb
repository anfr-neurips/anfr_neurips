{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 10000/10000 [00:28<00:00, 352.60it/s]\n",
      "Loading dataset: 100%|██████████| 10000/10000 [00:28<00:00, 347.06it/s]\n",
      "Loading dataset: 100%|██████████| 7797/7797 [00:27<00:00, 287.44it/s]\n",
      "Loading dataset: 100%|██████████| 7203/7203 [00:16<00:00, 446.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# perform inference on the test set using a trained model\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fl_bench.chest.src.dm_test import ChestDataModuleTest\n",
    "from fl_bench.chest.src.validator import Validator\n",
    "from fl_bench.networks.chest_nets import *\n",
    "import json\n",
    "import numpy as np\n",
    "from monai.transforms import Activations\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# make the directory path for the report with the optimal thresholds and the model\n",
    "suf_model = \"/simulate_job/app_server/FL_global_model.pt\"\n",
    "suf_report = \"/simulate_job/cross_site_val/cross_val_results.json\"\n",
    "root_path = # path to the trained model directory\n",
    "dm_pc = ChestDataModuleTest(\n",
    "    data_dir=root_path,\n",
    "    client_idx='client_padchest',\n",
    "    cache_rate=1.0,\n",
    ")\n",
    "dm_cxr = ChestDataModuleTest(\n",
    "    data_dir=root_path,\n",
    "    client_idx='client_cxr14',\n",
    "    cache_rate=1.0,\n",
    ")\n",
    "dm_cxp_young = ChestDataModuleTest(\n",
    "    data_dir=root_path,\n",
    "    client_idx='client_cxp_young',\n",
    "    cache_rate=1.0,\n",
    ")\n",
    "dm_cxp_old = ChestDataModuleTest(\n",
    "    data_dir=root_path,\n",
    "    client_idx='client_cxp_old',\n",
    "    cache_rate=1.0,\n",
    ")\n",
    "validator = Validator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_auroc(arch, method, seed):\n",
    "    model = eval(arch)(seed).cuda()\n",
    "\n",
    "    target_model = \"\"\n",
    "    model_path = target_model + suf_model\n",
    "\n",
    "    # load the checkpoint\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    # perform inference on the test set\n",
    "    pc_results = validator.run(model, dm_pc.test_dataloader)\n",
    "    cxr_results = validator.run(model, dm_cxr.test_dataloader)\n",
    "    cxp_young_results = validator.run(model, dm_cxp_young.test_dataloader)\n",
    "    cxp_old_results = validator.run(model, dm_cxp_old.test_dataloader)\n",
    "\n",
    "    return pc_results['mean_auroc'], cxr_results['mean_auroc'], cxp_young_results['mean_auroc'], cxp_old_results['mean_auroc']\n",
    "\n",
    "def get_pfl_test_auroc(arch, method, seed):\n",
    "    model = eval(arch)(seed).to('cuda:0')\n",
    "\n",
    "    target_model = \"\"\n",
    "    model_path_pc = \"\"\n",
    "    model_path_cxr = \"\"\n",
    "    model_path_cxp_young = \"\"\n",
    "    model_path_cxp_old = \"\"\n",
    "\n",
    "    # load the checkpoint\n",
    "    checkpoint = torch.load(model_path_pc)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    pc_results = validator.run(model, dm_pc.test_dataloader)\n",
    "\n",
    "    checkpoint = torch.load(model_path_cxr)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    cxr_results = validator.run(model, dm_cxr.test_dataloader)\n",
    "\n",
    "    checkpoint = torch.load(model_path_cxp_young)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    cxp_young_results = validator.run(model, dm_cxp_young.test_dataloader)\n",
    "\n",
    "    checkpoint = torch.load(model_path_cxp_old)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    cxp_old_results = validator.run(model, dm_cxp_old.test_dataloader)\n",
    "\n",
    "    return pc_results['mean_auroc'], cxr_results['mean_auroc'], cxp_young_results['mean_auroc'], cxp_old_results['mean_auroc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3_seed_auroc(arch, method, seed_list, func=get_test_auroc):\n",
    "    seed_dict = {}\n",
    "    pc_metrics = []\n",
    "    cxr_metrics = []\n",
    "    cxp_young_metrics = []\n",
    "    cxp_old_metrics = []\n",
    "    for seed in tqdm(seed_list):\n",
    "        seed_dict[seed] = func(arch, method, seed)\n",
    "        pc_metrics.append(seed_dict[seed][0])\n",
    "        cxr_metrics.append(seed_dict[seed][1])\n",
    "        cxp_young_metrics.append(seed_dict[seed][2])\n",
    "        cxp_old_metrics.append(seed_dict[seed][3])\n",
    "\n",
    "\n",
    "    print(f\"PC AUROC: \\nMean: {100*np.mean(pc_metrics)}\\nStd: {100*np.std(pc_metrics)}\\n\")\n",
    "    print(f\"CXR AUROC: \\nMean: {100*np.mean(cxr_metrics)}\\nStd: {100*np.std(cxr_metrics)}\\n\")\n",
    "    print(f\"CXP Young AUROC: \\nMean: {100*np.mean(cxp_young_metrics)}\\nStd: {100*np.std(cxp_young_metrics)}\\n\")\n",
    "    print(f\"CXP Old AUROC: \\nMean: {100*np.mean(cxp_old_metrics)}\\nStd: {100*np.std(cxp_old_metrics)}\\n\")\n",
    "    print(f\"Total AUROC: {100*np.mean([np.mean(pc_metrics), np.mean(cxr_metrics), np.mean(cxp_young_metrics), np.mean(cxp_old_metrics)])}\")\n",
    "    var1 = np.var(pc_metrics)\n",
    "    var2 = np.var(cxr_metrics)\n",
    "    var3 = np.var(cxp_young_metrics)\n",
    "    var4 = np.var(cxp_old_metrics)\n",
    "    std_total = np.sqrt((var1 + var2 + var3 + var4)/4)\n",
    "    print(f\"Total AUROC Std: {100*std_total}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation DataLoader: 100%|██████████| 100/100 [00:03<00:00, 32.10it/s]\n",
      "Validation DataLoader: 100%|██████████| 100/100 [00:02<00:00, 33.35it/s]\n",
      "Validation DataLoader: 100%|██████████| 78/78 [00:02<00:00, 31.88it/s]\n",
      "Validation DataLoader: 100%|██████████| 73/73 [00:02<00:00, 31.30it/s]\n",
      "Validation DataLoader: 100%|██████████| 100/100 [00:03<00:00, 32.55it/s]\n",
      "Validation DataLoader: 100%|██████████| 100/100 [00:02<00:00, 33.63it/s]\n",
      "Validation DataLoader: 100%|██████████| 78/78 [00:02<00:00, 32.81it/s]\n",
      "Validation DataLoader: 100%|██████████| 73/73 [00:02<00:00, 32.78it/s]\n",
      "Validation DataLoader: 100%|██████████| 100/100 [00:03<00:00, 32.44it/s]\n",
      "Validation DataLoader: 100%|██████████| 100/100 [00:02<00:00, 33.35it/s]\n",
      "Validation DataLoader: 100%|██████████| 78/78 [00:02<00:00, 32.54it/s]\n",
      "Validation DataLoader: 100%|██████████| 73/73 [00:02<00:00, 32.47it/s]\n",
      "100%|██████████| 3/3 [00:35<00:00, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC AUROC: \n",
      "Mean: 89.10805468466182\n",
      "Std: 0.03476624621040819\n",
      "\n",
      "CXR AUROC: \n",
      "Mean: 84.37405418596526\n",
      "Std: 0.0756157078910905\n",
      "\n",
      "CXP Young AUROC: \n",
      "Mean: 79.12829581384672\n",
      "Std: 0.1695321185951078\n",
      "\n",
      "CXP Old AUROC: \n",
      "Mean: 75.965183348437\n",
      "Std: 0.08457003941732374\n",
      "\n",
      "Total AUROC: 82.1438970082277\n",
      "Total AUROC Std: 0.10346455668226057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_3_seed_auroc('resnet_50_supervised', 'fedprox', [42, 1995, 99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pfl auroc\n",
    "get_3_seed_auroc('resnet_50_supervised', 'fedper', [42, 1995, 2024], func=get_pfl_test_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model, dm, val_thresholds):\n",
    "\n",
    "    transform_post = Activations(sigmoid=True)\n",
    "    model.eval()\n",
    "    metrics = {}\n",
    "    y = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dm.test_dataloader:\n",
    "            batch[\"image\"] = batch[\"image\"].to(\"cuda:0\")\n",
    "            batch[\"label\"] = batch[\"label\"].to(\"cuda:0\")\n",
    "            batch[\"preds\"] = model(batch[\"image\"])\n",
    "            batch[\"preds\"] = transform_post(batch[\"preds\"])\n",
    "            y.append(batch[\"label\"])\n",
    "            y_pred.append(batch[\"preds\"])\n",
    "\n",
    "        y = torch.cat(y)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "\n",
    "        y_pred_np = y_pred.numpy(force=True)\n",
    "        y_np = y.numpy(force=True)\n",
    "\n",
    "    bin_labels = (y_pred_np > val_thresholds).astype(np.int32)\n",
    "    # Metrics calculation (macro) over the whole set\n",
    "    total_cm = multilabel_confusion_matrix(y_true=y_np, y_pred=bin_labels)\n",
    "    eps = 1e-7\n",
    "    f1 = []\n",
    "    accuracy = []\n",
    "    for cls_cm in total_cm:\n",
    "        TP = cls_cm[1, 1]\n",
    "        TN = cls_cm[0, 0]\n",
    "        FP = cls_cm[0, 1]\n",
    "        FN = cls_cm[1, 0]\n",
    "        f1.append(2 * TP / (2 * TP + FN + FP + eps))\n",
    "        accuracy.append((TP + TN) / (TP + TN + FP + FN + eps))\n",
    "\n",
    "    metrics[\"macro_f1_score\"] = np.mean(f1)\n",
    "    metrics[\"macro_accuracy\"] = np.mean(accuracy)\n",
    "    # print(metrics)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_site_metrics(arch, method, seed):\n",
    "    model = eval(arch)(seed).cuda()\n",
    "\n",
    "    target_model = \"\"\n",
    "    model_path = target_model + suf_model\n",
    "\n",
    "    # load the checkpoint\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    report_path = target_model + suf_report\n",
    "    # read the json report and find the optimal thresholds field\n",
    "    with open(report_path, \"r\") as f:\n",
    "        report = json.load(f)\n",
    "        val_thresholds_pc = report['client_padchest']['SRV_server'][\"optimal_thresholds\"]\n",
    "        val_thresholds_cxr = report['client_cxr14']['SRV_server'][\"optimal_thresholds\"]\n",
    "        val_thresholds_cxp_young = report['client_cxp_young']['SRV_server'][\"optimal_thresholds\"]\n",
    "        val_thresholds_cxp_old = report['client_cxp_old']['SRV_server'][\"optimal_thresholds\"]\n",
    "    \n",
    "    pc_metrics = get_metrics(model, dm_pc, val_thresholds_pc)\n",
    "    cxr_metrics = get_metrics(model, dm_cxr, val_thresholds_cxr)\n",
    "    cxp_young_metrics = get_metrics(model, dm_cxp_young, val_thresholds_cxp_young)\n",
    "    cxp_old_metrics = get_metrics(model, dm_cxp_old, val_thresholds_cxp_old)\n",
    "    return pc_metrics, cxr_metrics, cxp_young_metrics, cxp_old_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_pfl_metrics(arch, method, seed):\n",
    "    model = eval(arch)(seed).cuda()\n",
    "    target_model = f\"{arch}_{method}_{seed}\"\n",
    "    report_path = target_model + suf_report\n",
    "    # read the json report and find the optimal thresholds field\n",
    "    with open(report_path, \"r\") as f:\n",
    "        report = json.load(f)\n",
    "        val_thresholds_pc = report['client_padchest']['client_padchest'][\"optimal_thresholds\"]\n",
    "        val_thresholds_cxr = report['client_cxr14']['client_cxr14'][\"optimal_thresholds\"]\n",
    "        val_thresholds_cxp_young = report['client_cxp_young']['client_cxp_young'][\"optimal_thresholds\"]\n",
    "        val_thresholds_cxp_old = report['client_cxp_old']['client_cxp_old'][\"optimal_thresholds\"]\n",
    "\n",
    "    model_path_pc = target_model + \"/simulate_job/app_client_padchest/models/best_model.pt\"\n",
    "    model_path_cxr = target_model + \"/simulate_job/app_client_cxr14/models/best_model.pt\"\n",
    "    model_path_cxp_young = target_model + \"/simulate_job/app_client_cxp_young/models/best_model.pt\"\n",
    "    model_path_cxp_old = target_model + \"/simulate_job/app_client_cxp_old/models/best_model.pt\"\n",
    "\n",
    "    # load the checkpoint\n",
    "    checkpoint = torch.load(model_path_pc)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    pc_metrics = get_metrics(model, dm_pc, val_thresholds_pc)\n",
    "\n",
    "    checkpoint = torch.load(model_path_cxr)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    cxr_metrics = get_metrics(model, dm_cxr, val_thresholds_cxr)\n",
    "\n",
    "    checkpoint = torch.load(model_path_cxp_young)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    cxp_young_metrics = get_metrics(model, dm_cxp_young, val_thresholds_cxp_young)\n",
    "\n",
    "    checkpoint = torch.load(model_path_cxp_old)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    cxp_old_metrics = get_metrics(model, dm_cxp_old, val_thresholds_cxp_old)\n",
    "\n",
    "    return pc_metrics, cxr_metrics, cxp_young_metrics, cxp_old_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3_seed_metrics(arch, method, seed_list, func=get_multi_site_metrics):\n",
    "    seed_dict = {}\n",
    "    pc_f1_metrics = []\n",
    "    cxr_f1_metrics = []\n",
    "    cxp_young_f1_metrics = []\n",
    "    cxp_old_f1_metrics = []\n",
    "    cxr_acc_metrics = []\n",
    "    pc_acc_metrics = []\n",
    "    cxp_young_acc_metrics = []\n",
    "    cxp_old_acc_metrics = []\n",
    "    for seed in tqdm(seed_list):\n",
    "        seed_dict[seed] = func(arch, method, seed)\n",
    "        pc_f1_metrics.append(seed_dict[seed][0]['macro_f1_score'])\n",
    "        cxr_f1_metrics.append(seed_dict[seed][1]['macro_f1_score'])\n",
    "        cxp_young_f1_metrics.append(seed_dict[seed][2]['macro_f1_score'])\n",
    "        cxp_old_f1_metrics.append(seed_dict[seed][3]['macro_f1_score'])\n",
    "        pc_acc_metrics.append(seed_dict[seed][0]['macro_accuracy'])\n",
    "        cxr_acc_metrics.append(seed_dict[seed][1]['macro_accuracy'])\n",
    "        cxp_young_acc_metrics.append(seed_dict[seed][2]['macro_accuracy'])\n",
    "        cxp_old_acc_metrics.append(seed_dict[seed][3]['macro_accuracy'])\n",
    "\n",
    "\n",
    "    print(f\"PC F1: \\nMean: {100*np.mean(pc_f1_metrics)}\\nStd: {100*np.std(pc_f1_metrics)}\\n\")\n",
    "    print(f\"CXR F1: \\nMean: {100*np.mean(cxr_f1_metrics)}\\nStd: {100*np.std(cxr_f1_metrics)}\\n\")\n",
    "    print(f\"CXP Young F1: \\nMean: {100*np.mean(cxp_young_f1_metrics)}\\nStd: {100*np.std(cxp_young_f1_metrics)}\\n\")\n",
    "    print(f\"CXP Old F1: \\nMean: {100*np.mean(cxp_old_f1_metrics)}\\nStd: {100*np.std(cxp_old_f1_metrics)}\\n\")\n",
    "    print(f\"Total F1: {100*np.mean([np.mean(pc_f1_metrics), np.mean(cxr_f1_metrics), np.mean(cxp_young_f1_metrics), np.mean(cxp_old_f1_metrics)])}\")\n",
    "    var1 = np.var(pc_f1_metrics)\n",
    "    var2 = np.var(cxr_f1_metrics)\n",
    "    var3 = np.var(cxp_young_f1_metrics)\n",
    "    var4 = np.var(cxp_old_f1_metrics)\n",
    "    std_total = np.sqrt((var1 + var2 + var3 + var4)/4)\n",
    "    print(f\"Total F1 Std: {100*std_total}\\n\")\n",
    "\n",
    "    print(f\"PC Acc: \\nMean: {100*np.mean(pc_acc_metrics)}\\nStd: {100*np.std(pc_acc_metrics)}\\n\")\n",
    "    print(f\"CXR Acc: \\nMean: {100*np.mean(cxr_acc_metrics)}\\nStd: {100*np.std(cxr_acc_metrics)}\\n\")\n",
    "    print(f\"CXP Young Acc: \\nMean: {100*np.mean(cxp_young_acc_metrics)}\\nStd: {100*np.std(cxp_young_acc_metrics)}\\n\")\n",
    "    print(f\"CXP Old Acc: \\nMean: {100*np.mean(cxp_old_acc_metrics)}\\nStd: {100*np.std(cxp_old_acc_metrics)}\\n\")\n",
    "\n",
    "    print(f\"Total Acc: {100*np.mean([np.mean(pc_acc_metrics), np.mean(cxr_acc_metrics), np.mean(cxp_young_acc_metrics), np.mean(cxp_old_acc_metrics)])}\")\n",
    "    # Grouped Std\n",
    "    var1 = np.var(pc_acc_metrics)\n",
    "    var2 = np.var(cxr_acc_metrics)\n",
    "    var3 = np.var(cxp_young_acc_metrics)\n",
    "    var4 = np.var(cxp_old_acc_metrics)\n",
    "    std_total = np.sqrt((var1 + var2 + var3 + var4)/4)\n",
    "    print(f\"Total Acc Std: {100*std_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:43<00:00, 34.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC F1: \n",
      "Mean: 43.36098475939678\n",
      "Std: 0.22224987498085474\n",
      "\n",
      "CXR F1: \n",
      "Mean: 39.10883599227938\n",
      "Std: 0.26266691840025225\n",
      "\n",
      "CXP Young F1: \n",
      "Mean: 47.26411166448809\n",
      "Std: 0.4783709901928217\n",
      "\n",
      "CXP Old F1: \n",
      "Mean: 44.89886147960561\n",
      "Std: 0.3575812474246077\n",
      "\n",
      "Total F1: 43.65819847394247\n",
      "Total F1 Std: 0.3446346143811912\n",
      "\n",
      "PC Acc: \n",
      "Mean: 82.82374999917175\n",
      "Std: 0.2484137174126345\n",
      "\n",
      "CXR Acc: \n",
      "Mean: 78.17208333255161\n",
      "Std: 0.5309134554864734\n",
      "\n",
      "CXP Young Acc: \n",
      "Mean: 72.42796374581127\n",
      "Std: 0.9392042631502389\n",
      "\n",
      "CXP Old Acc: \n",
      "Mean: 71.3296543097136\n",
      "Std: 0.7130748633492264\n",
      "\n",
      "Total Acc: 76.18836284681205\n",
      "Total Acc Std: 0.6584373320361347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_3_seed_metrics('seresnet_50_supervised', 'scaffold', [99,1,42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pfl metrics\n",
    "get_3_seed_metrics('seresnet50_pretrained', 'fedper', [2024,1995,42], get_multi_pfl_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
